# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞ –∏ –¥–∞–ª—å–Ω–µ–π—à–∏–µ –¥–µ–π—Å—Ç–≤–∏—è

## ‚úÖ –ß—Ç–æ —É—Å–ø–µ—à–Ω–æ —Å–¥–µ–ª–∞–Ω–æ

1. **–°—Ö–µ–º–∞ –ø–∏—Ç–∞–Ω–∏—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞ –Ω–∞ "–í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"** - —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Intel Arc iGPU
2. **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞–º—è—Ç–∏ —É–∂–µ –±—ã–ª–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏** - LargePageMinimum, DisablePagingExecutive –∏ SecondLevelDataCache —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ
3. **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã Intel GMM –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã** (DedicatedSegmentSize=4096, DynamicMemoryManagement=0, PreallocatedVram=4096)

## ‚ö†Ô∏è –ö–ª—é—á–µ–≤–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ

**–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≤—Å–µ–≥–æ ~2 –ì–ë VRAM** –≤–º–µ—Å—Ç–æ –æ–∂–∏–¥–∞–µ–º—ã—Ö 4 –ì–ë. –≠—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç, —á—Ç–æ **BIOS –≤–∞—à–µ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –≤—ã–¥–µ–ª–µ–Ω–∏–µ VRAM** - —ç—Ç–æ —Ç–∏–ø–∏—á–Ω–æ –¥–ª—è –Ω–æ—É—Ç–±—É–∫–æ–≤, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏ —á–∞—Å—Ç–æ –±–ª–æ–∫–∏—Ä—É—é—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É DVMT Pre-Allocated –≤ BIOS.

## üìå –ß—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ (–ø–æ—à–∞–≥–æ–≤–æ)

### 1. –ù–ï –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ base –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å Python 3.13!
–≠—Ç–æ **–≥–ª–∞–≤–Ω–∞—è –æ—à–∏–±–∫–∞**, –∫–æ—Ç–æ—Ä—É—é –¥–µ–ª–∞—é—Ç –º–Ω–æ–≥–∏–µ. Base –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å Python 3.13 **–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç** –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Intel Arc iGPU.

### 2. –°–æ–∑–¥–∞–π—Ç–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ Conda –¥–ª—è LLM —Å Python 3.11

–ó–∞–∫—Ä–æ–π—Ç–µ —Ç–µ–∫—É—â–∏–π PowerShell (–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä) –∏ –æ—Ç–∫—Ä–æ–π—Ç–µ **–æ–±—ã—á–Ω—ã–π PowerShell (–±–µ–∑ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞)**, –∑–∞—Ç–µ–º –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:

```powershell
# –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å Python 3.11
conda create -n llm-arc python=3.11 libuv -y

# –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –µ–≥–æ
conda activate llm-arc

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã
pip install --pre --upgrade ipex-llm[xpu] --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
pip install transformers==4.42.0 accelerate==0.29.3 bitsandbytes==0.43.0 sentence-transformers==2.2.2 chromadb==0.3.23
```

### 3. –°–æ–∑–¥–∞–π—Ç–µ —Å—Ç–∞—Ä—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞

–í –ø–∞–ø–∫–µ –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `start_optimized.ps1` —Å–æ —Å–ª–µ–¥—É—é—â–∏–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º:

```powershell
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Intel XPU
$env:SYCL_CACHE_PERSISTENT = "1"
$env:ENABLE_LP64 = "1"
$env:SYCL_DEVICE_FILTER = "level_zero:gpu"
$env:ONEAPI_DEVICE_SELECTOR = "level_zero:*"
$env:OMP_NUM_THREADS = "8"
$env:KMP_BLOCKTIME = "0"

# –°–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞ SYCL
$cacheDir = "$pwd\.sycl_cache"
if (-not (Test-Path $cacheDir)) {
    New-Item -Path $cacheDir -ItemType Directory -Force | Out-Null
}
$env:SYCL_CACHE_DIR = $cacheDir

# –ó–∞–ø—É—Å–∫ Python —Å –≤—ã—Å–æ–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
Start-Process -FilePath "python" -ArgumentList $args -NoNewWindow -Wait -PriorityClass High
```

### 4. –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å 2 –ì–ë VRAM

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `run_llm.py`:

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import intel_extension_for_pytorch as ipex

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–ª–ª–æ–∫–∞—Ç–æ—Ä–∞ –ø–∞–º—è—Ç–∏
torch.xpu.set_allocator(torch.xpu.XPUCachingAllocator)
torch.xpu.empty_cache()

# 4-–±–∏—Ç–Ω–∞—è –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è 2 –ì–ë VRAM
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    cpu_embedding=True  # –ö–†–ò–¢–ò–ß–ù–û –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –õ–ï–ì–ö–û–ô –º–æ–¥–µ–ª–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ 3B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
model_id = "microsoft/phi-2"  # –ò–ª–∏ "Qwen/Qwen2-1.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_id)

model = AutoModelForCausalLM.from_pretrained(
    model_id,
    quantization_config=bnb_config,
    max_memory={"xpu": "1.8GB", "cpu": "8GB"},  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å –¥–ª—è —Å–∏—Å—Ç–µ–º—ã
    torch_dtype=torch.bfloat16,
    trust_remote_code=False,
    low_cpu_mem_usage=True
)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ IPEX –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
model = ipex.llm.optimize(
    model,
    dtype=torch.bfloat16,
    inplace=True,
    auto_cast="matmul",  # –ê–∫—Ç–∏–≤–∞—Ü–∏—è XMX –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    graph_mode=True,     # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    weights_prepack=True # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–µ–∫ –¥–æ—Å—Ç—É–ø–∞
)

# –ü—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
prompt = "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ 4-–±–∏—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π?"
inputs = tokenizer(prompt, return_tensors="pt").to("xpu")
outputs = model.generate(**inputs, max_new_tokens=100)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

### 5. –ó–∞–ø—É—Å–∫ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏

```powershell
# –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞
cd C:\–ø—É—Ç—å\–∫\–≤–∞—à–µ–º—É_–ø—Ä–æ–µ–∫—Ç—É


# 3. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install --pre torch==2.7.1+xpu torchvision==0.22.1+xpu torchaudio==2.7.1+xpu \
  --index-url https://download.pytorch.org/whl/nightly/xpu
pip install ipex-llm[xpu] --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/

)

# –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
conda activate lfp_bot_py311 —á–µ—Ä–µ–∑ –∑–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ D:\DEV\LFP-TGbot-LLM-RAG-Cursor\setup_env.ps1,
 –∏–ª–∏ –∑–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ D:\DEV\LFP-TGbot-LLM-RAG\start_bot.ps1

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —á–µ—Ä–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç start_optimized.ps1(
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Intel XPU
$env:SYCL_CACHE_PERSISTENT = "1"
$env:ENABLE_LP64 = "1"
$env:SYCL_DEVICE_FILTER = "level_zero:gpu"
$env:ONEAPI_DEVICE_SELECTOR = "level_zero:*"
$env:OMP_NUM_THREADS = "8"
$env:KMP_BLOCKTIME = "0"

# –°–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞ SYCL
$cacheDir = "$pwd\.sycl_cache"
if (-not (Test-Path $cacheDir)) {
    New-Item -Path $cacheDir -ItemType Directory -Force | Out-Null
}
$env:SYCL_CACHE_DIR = $cacheDir

# –ó–∞–ø—É—Å–∫ Python —Å –≤—ã—Å–æ–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
Start-Process -FilePath "python" -ArgumentList $args -NoNewWindow -Wait -PriorityClass High

)
.\start_optimized.ps1 run_llm.py
```
()
## üí° –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

1. **–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Python 3.13 –¥–ª—è LLM –Ω–∞ Intel Arc** - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ torch-xpu –¥–ª—è Python 3.12 –∏ –≤—ã—à–µ –ø–æ–∫–∞ –Ω–µ –ø–æ–ª–Ω–∞—è
2. **–í—Å–µ–≥–¥–∞ –∑–∞–ø—É—Å–∫–∞–π—Ç–µ —á–µ—Ä–µ–∑ `start_optimized.ps1`** –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –∑–∞–ø—É—Å–∫–æ–º –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏
3. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ –¥–æ 3B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** (Phi-2, Qwen2-1.5B) - —Å 2 –ì–ë VRAM –º–æ–¥–µ–ª–∏ –±–æ–ª—å—à–µ 3B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ –∑–∞–ø—É—Å—Ç—è—Ç—Å—è
4. **–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `cpu_embedding=True`** - —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM
5.**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å 2 –ì–ë VRAM
(
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import intel_extension_for_pytorch as ipex

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–ª–ª–æ–∫–∞—Ç–æ—Ä–∞ –ø–∞–º—è—Ç–∏
torch.xpu.set_allocator(torch.xpu.XPUCachingAllocator)
torch.xpu.empty_cache()

# 4-–±–∏—Ç–Ω–∞—è –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è 2 –ì–ë VRAM
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    cpu_embedding=True  # –ö–†–ò–¢–ò–ß–ù–û –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –õ–ï–ì–ö–û–ô –º–æ–¥–µ–ª–∏ (–¥–æ 3B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
model_id = "microsoft/phi-2"  # –ò–ª–∏ "Qwen/Qwen2-1.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_id)

model = AutoModelForCausalLM.from_pretrained(
    model_id,
    quantization_config=bnb_config,
    max_memory={"xpu": "1.8GB", "cpu": "8GB"},  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å –¥–ª—è —Å–∏—Å—Ç–µ–º—ã
    torch_dtype=torch.bfloat16,
    trust_remote_code=False,
    low_cpu_mem_usage=True
)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ IPEX –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
model = ipex.llm.optimize(
    model,
    dtype=torch.bfloat16,
    inplace=True,
    auto_cast="matmul",  # –ê–∫—Ç–∏–≤–∞—Ü–∏—è XMX –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    graph_mode=True,     # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    weights_prepack=True # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–µ–∫ –¥–æ—Å—Ç—É–ø–∞
)
)

## üìä –û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

–° –≤–∞—à–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π (Intel Arc iGPU, 2 –ì–ë VRAM) –≤—ã –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∏—Ç—å:
- –°–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: 8-12 —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫ –¥–ª—è –º–æ–¥–µ–ª–µ–π –¥–æ 2.7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ VRAM: ~1.8 –ì–ë (–æ—Å—Ç–∞–≤–ª—è—è –∑–∞–ø–∞—Å –¥–ª—è —Å–∏—Å—Ç–µ–º—ã)
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–æ–¥–µ–ª–µ–π: –¥–æ 3B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ 4-–±–∏—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ

–≠—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á —Å LLM, –Ω–µ —Ç—Ä–µ–±—É—é—â–∏—Ö –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π.